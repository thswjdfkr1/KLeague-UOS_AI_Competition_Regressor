{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPbHLvwJq047PdtOKOvmNiN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install -Uq tabpfn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hXmcDRDMMaal","executionInfo":{"status":"ok","timestamp":1770786737520,"user_tz":-540,"elapsed":6949,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"f80fb110-828f-446d-b35d-fcbb31fb2c63"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.0/611.0 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SfrPPTFetosv"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import random\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.model_selection import GroupKFold\n","\n","from tabpfn import TabPFNRegressor\n","from tabpfn.constants import ModelVersion\n","\n","import torch\n","\n","import gc"]},{"cell_type":"code","source":["def corr_feature_selection(df, threshold=0.95):\n","\n","    corr = df.corr(numeric_only=True).abs()\n","    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n","\n","    drop_cols = [col for col in upper.columns if any(upper[col] > threshold)]\n","\n","    df = df.drop(columns=drop_cols)\n","\n","    return df, drop_cols"],"metadata":{"id":"kerg9BdfMLZV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# setting"],"metadata":{"id":"f2ZTN3O7P0Pg"}},{"cell_type":"code","source":["file_path = '/content/drive/MyDrive/1데이콘/K리그-서울시립대공개AI경진대회/dataset/'\n","\n","SEED = 810\n","\n","device = \"cuda\" if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"Lgrd7ZPkG-Q1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def seed_every(seed=SEED):\n","  random.seed(seed)\n","  os.environ['PYTHONHASHSEED'] = str(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed(seed)\n","  torch.backends.cudnn.deterministic = True\n","  torch.backends.cudnn.benchmark = False\n","\n","seed_every(SEED)"],"metadata":{"id":"KDwGnnN7F04V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def euclid_np(pred_xy, true_xy):\n","    return float(np.mean(np.sqrt(((pred_xy - true_xy) ** 2).sum(axis=1))))"],"metadata":{"id":"As8JKvysM03h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# modeling"],"metadata":{"id":"dSONm4fw-hTo"}},{"cell_type":"code","source":["def make_model():\n","    m = TabPFNRegressor.create_default_for_version(ModelVersion.V2)\n","\n","    m.ignore_pretraining_limits = True\n","    m.n_estimators = 16\n","    m.average_before_softmax = True\n","    m.batch_size_inference = 32\n","    m.subsample_features = 0.8\n","    m.random_state = SEED\n","    m.device = device\n","\n","    return m"],"metadata":{"id":"qDjaPudfrE75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fit(Xtr, yd):\n","  model = make_model()\n","  model.fit(Xtr, yd)\n","\n","  return model"],"metadata":{"id":"4EpI0-yoOOVk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Load"],"metadata":{"id":"0ex5x3yaQWZL"}},{"cell_type":"code","source":["train_df = pd.read_parquet(file_path + 'x_train_full.parquet')\n","test_df = pd.read_parquet(file_path + 'x_test_full.parquet')\n","\n","y_dx_t = np.load(file_path + 'y_dx.npy')\n","y_dy_t = np.load(file_path + 'y_dy.npy')\n","\n","train = train_df.copy()\n","test = test_df.copy()\n","\n","y_dx = y_dx_t.copy()\n","y_dy = y_dy_t.copy()"],"metadata":{"id":"qoxKU377QXyw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CV Loop"],"metadata":{"id":"x-1UZVtmR8Bv"}},{"cell_type":"code","source":["train_start_x = train[\"start_x_t0\"].to_numpy()\n","train_start_y = train[\"start_y_t0\"].to_numpy()\n","test_start_x  = test[\"start_x_t0\"].to_numpy()\n","test_start_y  = test[\"start_y_t0\"].to_numpy()\n","\n","test_eps = test[\"game_episode\"].tolist()\n","train_game = train[\"game_id\"].to_numpy()\n","\n","drop_cols = [\"game_episode\", \"start_x_t0\", \"start_y_t0\"]\n","x_all = train.drop(columns=drop_cols).fillna(0.0)\n","x_test = test.drop(columns=drop_cols).fillna(0.0)\n","\n","groups = train_game"],"metadata":{"id":"47YvZ9Wwm-Gq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["N_OUTER_FOLDS = 5\n","N_INNER_FOLDS = 3\n","\n","CLIP_OUTPUT = True"],"metadata":{"id":"yZic7J3qnTlR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outer_gkf = GroupKFold(n_splits=N_OUTER_FOLDS)\n","\n","best_vals = []\n","pred_test_x_folds = []\n","pred_test_y_folds = []"],"metadata":{"id":"Cq8oVPOlSECn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_target_encoding(X_train, y_dx_train, y_dy_train, X_val, X_test, col_name=\"player_id_curr_t0\"):\n","    # Target encoding with mean dx/dy\n","    df_stat = X_train[[col_name]].copy()\n","    df_stat[\"target_dx\"] = y_dx_train\n","    df_stat[\"target_dy\"] = y_dy_train\n","\n","    stats = df_stat.groupby(col_name).agg({\n","        \"target_dx\": \"mean\",\n","        \"target_dy\": \"mean\"\n","    }).reset_index()\n","\n","    stats.columns = [col_name, f\"{col_name}_mean_dx\", f\"{col_name}_mean_dy\"]\n","\n","    global_mean_dx = y_dx_train.mean()\n","    global_mean_dy = y_dy_train.mean()\n","\n","    X_train_out = X_train.merge(stats, on=col_name, how=\"left\")\n","    X_val_out   = X_val.merge(stats, on=col_name, how=\"left\")\n","    X_test_out  = X_test.merge(stats, on=col_name, how=\"left\")\n","\n","    cols = [f\"{col_name}_mean_dx\", f\"{col_name}_mean_dy\"]\n","\n","    # Fill missing values with global mean\n","    for df in [X_train_out, X_val_out, X_test_out]:\n","        df[cols[0]] = df[cols[0]].fillna(global_mean_dx)\n","        df[cols[1]] = df[cols[1]].fillna(global_mean_dy)\n","\n","    return X_train_out, X_val_out, X_test_out"],"metadata":{"id":"qVW6-DQ1udxD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for fold, (tr_idx, val_idx) in enumerate(outer_gkf.split(x_all, groups = groups)):\n","  print(f\"\\n===== Outer Fold {fold} =====\")\n","\n","  # data split\n","  x_tr = x_all.iloc[tr_idx].copy()\n","  x_val = x_all.iloc[val_idx].copy()\n","\n","  ydx_tr = y_dx[tr_idx]\n","  ydy_tr = y_dy[tr_idx]\n","  ydx_val = y_dx[val_idx]\n","  ydy_val = y_dy[val_idx]\n","\n","  val_sx = train_start_x[val_idx]\n","  val_sy = train_start_y[val_idx]\n","\n","  x_test_curr = x_test.copy()\n","\n","  # Target Encoding\n","  # Player ID\n","  x_tr, x_val, x_test_curr = add_target_encoding(\n","      x_tr, ydx_tr, ydy_tr, x_val, x_test_curr, col_name='player_id_curr_t0'\n","  )\n","  # team id\n","  x_tr, x_val, x_test_curr = add_target_encoding(\n","      x_tr, ydx_tr, ydy_tr, x_val, x_test_curr, col_name='team_id_curr_t0'\n","  )\n","  # opp team id\n","  x_tr, x_val, x_test_curr = add_target_encoding(\n","      x_tr, ydx_tr, ydy_tr, x_val, x_test_curr, col_name='new_opp_team_id_curr_t0'\n","  )\n","\n","  # remove game_id befor training\n","  drop_features = ['game_id']\n","  x_tr = x_tr.drop(columns=drop_features, errors = 'ignore')\n","  x_val = x_val.drop(columns=drop_features, errors = 'ignore')\n","  x_test_curr = x_test_curr.drop(columns=drop_features, errors = 'ignore')\n","\n","  # 1: Inner CV for OOF\n","  inner_groups = groups[tr_idx]\n","  inner_gkf = GroupKFold(n_splits=N_INNER_FOLDS)\n","\n","  oof_pred1_dx = np.zeros(len(tr_idx), dtype=np.float64)\n","  oof_pred1_dy = np.zeros(len(tr_idx), dtype=np.float64)\n","\n","  x_tr_reset = x_tr.reset_index(drop=True)\n","  ydx_tr_local = ydx_tr\n","  ydy_tr_local = ydy_tr\n","\n","  for inner_fold, (itr, iva) in enumerate(inner_gkf.split(x_tr_reset, groups=inner_groups)):\n","    x_itr = x_tr_reset.iloc[itr]\n","    x_iva = x_tr_reset.iloc[iva]\n","\n","    mx1, my1 = fit(x_itr, ydx_tr_local[itr]), fit(x_itr, ydy_tr_local[itr])\n","\n","    oof_pred1_dx[iva] = mx1.predict(x_iva)\n","    oof_pred1_dy[iva] = my1.predict(x_iva)\n","    gc.collect()\n","\n","  # Calculate Residuals\n","  res_tr_dx = ydx_tr_local - oof_pred1_dx\n","  res_tr_dy = ydy_tr_local - oof_pred1_dy\n","\n","  x_tr_stage2 = x_tr_reset.copy()\n","  x_tr_stage2[\"pred1_dx\"] = oof_pred1_dx\n","  x_tr_stage2[\"pred1_dy\"] = oof_pred1_dy\n","\n","  # 6. Fit Final Stage 1 Models\n","  mx1_full, my1_full = fit(x_tr, ydx_tr), fit(x_tr, ydy_tr)\n","\n","  pred1_val_dx = mx1_full.predict(x_val)\n","  pred1_val_dy = my1_full.predict(x_val)\n","  pred1_test_dx = mx1_full.predict(x_test_curr)\n","  pred1_test_dy = my1_full.predict(x_test_curr)\n","\n","  # 7. Fit Stage 2 Models (Residuals)\n","  mx2, my2 = fit(x_tr_stage2, res_tr_dx), fit(x_tr_stage2, res_tr_dy)\n","\n","  x_val_stage2 = x_val.copy()\n","  x_val_stage2[\"pred1_dx\"] = pred1_val_dx\n","  x_val_stage2[\"pred1_dy\"] = pred1_val_dy\n","\n","  x_test_stage2 = x_test_curr.copy()\n","  x_test_stage2[\"pred1_dx\"] = pred1_test_dx\n","  x_test_stage2[\"pred1_dy\"] = pred1_test_dy\n","\n","  pred2_val_dx = mx2.predict(x_val_stage2)\n","  pred2_val_dy = my2.predict(x_val_stage2)\n","\n","  pred2_test_dx = mx2.predict(x_test_stage2)\n","  pred2_test_dy = my2.predict(x_test_stage2)\n","\n","  # 8. Ensemble Stage 1 + Stage 2\n","  final_val_dx = pred1_val_dx + pred2_val_dx\n","  final_val_dy = pred1_val_dy + pred2_val_dy\n","  final_test_dx = pred1_test_dx + pred2_test_dx\n","  final_test_dy = pred1_test_dy + pred2_test_dy\n","\n","  # Restore coordinates & Clip\n","  val_pred_x = val_sx + final_val_dx\n","  val_pred_y = val_sy + final_val_dy\n","\n","  if CLIP_OUTPUT:\n","    val_pred_x = np.clip(val_pred_x, 0.0, 105.0)\n","    val_pred_y = np.clip(val_pred_y, 0.0, 68.0)\n","\n","  val_true_x = val_sx + ydx_val\n","  val_true_y = val_sy + ydy_val\n","\n","  val_dist = euclid_np(\n","      np.stack([val_pred_x, val_pred_y], axis=1),\n","      np.stack([val_true_x, val_true_y], axis=1),\n","      )\n","  best_vals.append(val_dist)\n","  print(f\"Outer Fold {fold}: best val_dist = {val_dist:.5f}\")\n","\n","  test_pred_x = test_start_x + final_test_dx\n","  test_pred_y = test_start_y + final_test_dy\n","\n","  if CLIP_OUTPUT:\n","      test_pred_x = np.clip(test_pred_x, 0.0, 105.0)\n","      test_pred_y = np.clip(test_pred_y, 0.0, 68.0)\n","\n","  pred_test_x_folds.append(test_pred_x)\n","  pred_test_y_folds.append(test_pred_y)\n","\n","  gc.collect()\n","\n","print(\"\\n========== CV Summary (2-Stage Residual) ==========\")\n","for f, v in enumerate(best_vals):\n","    print(f\"Fold {f}: best val_dist = {v:.5f}\")\n","print(f\"Mean val_dist = {np.mean(best_vals):.5f}\")\n","print(f\"Std  val_dist = {np.std(best_vals):.5f}\")\n","\n","pred_test_x = np.mean(np.stack(pred_test_x_folds, axis=0), axis=0)\n","pred_test_y = np.mean(np.stack(pred_test_y_folds, axis=0), axis=0)\n","\n","if CLIP_OUTPUT:\n","    pred_test_x = np.clip(pred_test_x, 0.0, 105.0)\n","    pred_test_y = np.clip(pred_test_y, 0.0, 68.0)\n","\n","out_df = pd.DataFrame({\n","    \"game_episode\": test_eps,\n","    \"end_x\": pred_test_x,\n","    \"end_y\": pred_test_y,\n","})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8wLSkRHASczP","outputId":"e8d4ec79-7603-415d-8449-e4f6632a44ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","===== Outer Fold 0 =====\n"]}]},{"cell_type":"markdown","source":["# summary & submission"],"metadata":{"id":"rj6Y_SILEgwF"}},{"cell_type":"code","source":["sample_sub = pd.read_csv(file_path + 'sample_submission.csv')\n","sub = sample_sub.merge(out_df, on=\"game_episode\", how=\"left\")\n","\n","if \"end_x_y\" in sub.columns:\n","    sub[\"end_x\"] = sub[\"end_x_y\"]\n","    sub[\"end_y\"] = sub[\"end_y_y\"]\n","\n","sub[\"end_x\"] = sub[\"end_x\"].clip(0.0, 105.0)\n","sub[\"end_y\"] = sub[\"end_y\"].clip(0.0, 68.0)\n","\n","sub = sub[[\"game_episode\", \"end_x\", \"end_y\"]]\n","sub.to_csv(file_path + 'output/submission4', index=False)\n","print(\"Saved\")"],"metadata":{"id":"Bel4TZe4ytgT"},"execution_count":null,"outputs":[]}]}
