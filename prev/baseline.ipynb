{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPfl5O6fyL/092mvoQpa1Vw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BHBBp4s8gLSN"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","import torch\n","from torch import nn\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n","from torch.utils.data import Dataset, DataLoader\n","import os\n","TRAIN_PATH = \"/content/drive/MyDrive/1데이콘/Track1알고리즘부문:K리그-서울시립대공개AI경진대회/dataset/train.csv\"\n","BATCH_SIZE = 64\n","EPOCHS = 5\n","LR = 1e-3\n","HIDDEN_DIM = 64\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Using device:\", DEVICE)\n","\n","df = pd.read_csv(TRAIN_PATH)\n","df = df.sort_values([\"game_episode\", \"time_seconds\"]).reset_index(drop=True)\n","\n","episodes = []\n","targets = []\n","\n","for _, g in tqdm(df.groupby(\"game_episode\")):\n","    g = g.reset_index(drop=True)\n","    if len(g) < 2:\n","        continue\n","\n","    # 정규화된 좌표 준비\n","    sx = g[\"start_x\"].values / 105.0\n","    sy = g[\"start_y\"].values / 68.0\n","    ex = g[\"end_x\"].values   / 105.0\n","    ey = g[\"end_y\"].values   / 68.0\n","\n","    coords = []\n","    for i in range(len(g)):\n","        # 항상 start는 들어감\n","        coords.append([sx[i], sy[i]])\n","        # 마지막 행 이전까지만 end를 넣음 (마지막 end는 타깃이므로)\n","        if i < len(g) - 1:\n","            coords.append([ex[i], ey[i]])\n","\n","    seq = np.array(coords, dtype=\"float32\")        # [T, 2]\n","    target = np.array([ex[-1], ey[-1]], dtype=\"float32\")  # 마지막 행 end_x, end_y\n","\n","    episodes.append(seq)\n","    targets.append(target)\n","\n","print(\"에피소드 수 : \", len(episodes))\n","\n","class EpisodeDataset(Dataset):\n","    def __init__(self, episodes, targets):\n","        self.episodes = episodes\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.episodes)\n","\n","    def __getitem__(self, idx):\n","        seq = torch.tensor(self.episodes[idx])   # [T, 2]\n","        tgt = torch.tensor(self.targets[idx])    # [2]\n","        length = seq.size(0)\n","        return seq, length, tgt\n","\n","def collate_fn(batch):\n","    seqs, lengths, tgts = zip(*batch)\n","    lengths = torch.tensor(lengths, dtype=torch.long)\n","    padded = pad_sequence(seqs, batch_first=True)  # [B, T, 2]\n","    tgts = torch.stack(tgts, dim=0)                # [B, 2]\n","    return padded, lengths, tgts\n","\n","# 에피소드 단위 train / valid split\n","idx_train, idx_valid = train_test_split(\n","    np.arange(len(episodes)), test_size=0.2, random_state=42\n",")\n","\n","episodes_train = [episodes[i] for i in idx_train]\n","targets_train  = [targets[i]  for i in idx_train]\n","episodes_valid = [episodes[i] for i in idx_valid]\n","targets_valid  = [targets[i]  for i in idx_valid]\n","\n","train_loader = DataLoader(\n","    EpisodeDataset(episodes_train, targets_train),\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    collate_fn=collate_fn,\n",")\n","\n","valid_loader = DataLoader(\n","    EpisodeDataset(episodes_valid, targets_valid),\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    collate_fn=collate_fn,\n",")\n","\n","print(\"train episodes:\", len(episodes_train), \"valid episodes:\", len(episodes_valid))\n","\n","class LSTMBaseline(nn.Module):\n","    def __init__(self, input_dim=2, hidden_dim=64):\n","        super().__init__()\n","        self.lstm = nn.LSTM(\n","            input_size=input_dim,\n","            hidden_size=hidden_dim,\n","            num_layers=1,\n","            batch_first=True,\n","        )\n","        self.fc = nn.Linear(hidden_dim, 2)  # (x_norm, y_norm)\n","\n","    def forward(self, x, lengths):\n","        # x: [B, T, 2], lengths: [B]\n","        packed = pack_padded_sequence(\n","            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n","        )\n","        _, (h_n, _) = self.lstm(packed)\n","        h_last = h_n[-1]      # [B, H] 마지막 layer의 hidden state\n","        out = self.fc(h_last) # [B, 2]\n","        return out\n","\n","model = LSTMBaseline(input_dim=2, hidden_dim=HIDDEN_DIM).to(DEVICE)\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","\n","best_dist = float(\"inf\")\n","best_model_state = None\n","\n","for epoch in range(1, EPOCHS + 1):\n","    # --- Train ---\n","    model.train()\n","    total_loss = 0.0\n","\n","    for X, lengths, y in tqdm(train_loader):\n","        X, lengths, y = X.to(DEVICE), lengths.to(DEVICE), y.to(DEVICE)\n","\n","        optimizer.zero_grad()\n","        pred = model(X, lengths)\n","        loss = criterion(pred, y)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item() * X.size(0)\n","\n","    train_loss = total_loss / len(train_loader.dataset)\n","\n","    # --- Valid: 평균 유클리드 거리 ---\n","    model.eval()\n","    dists = []\n","\n","    with torch.no_grad():\n","        for X, lengths, y in tqdm(valid_loader):\n","            X, lengths, y = X.to(DEVICE), lengths.to(DEVICE), y.to(DEVICE)\n","            pred = model(X, lengths)\n","\n","            pred_np = pred.cpu().numpy()\n","            true_np = y.cpu().numpy()\n","\n","            pred_x = pred_np[:, 0] * 105.0\n","            pred_y = pred_np[:, 1] * 68.0\n","            true_x = true_np[:, 0] * 105.0\n","            true_y = true_np[:, 1] * 68.0\n","\n","            dist = np.sqrt((pred_x - true_x) ** 2 + (pred_y - true_y) ** 2)\n","            dists.append(dist)\n","\n","    mean_dist = np.concatenate(dists).mean()  # 평균 유클리드 거리\n","\n","    print(\n","        f\"[Epoch {epoch}] \"\n","        f\"train_loss={train_loss:.4f} | \"\n","        f\"valid_mean_dist={mean_dist:.4f}\"\n","    )\n","\n","    # ----- BEST MODEL 업데이트 -----\n","    if mean_dist < best_dist:\n","        best_dist = mean_dist\n","        best_model_state = model.state_dict().copy()\n","        print(f\" --> Best model updated! (dist={best_dist:.4f})\")\n","\n","# Best Model Load\n","model.load_state_dict(best_model_state)\n","model.eval()\n","\n","test_meta = pd.read_csv(\"/content/drive/MyDrive/1데이콘/Track1알고리즘부문:K리그-서울시립대공개AI경진대회/dataset/test.csv\")\n","submission = pd.read_csv(\"/content/drive/MyDrive/1데이콘/Track1알고리즘부문:K리그-서울시립대공개AI경진대회/dataset/sample_submission.csv\")\n","\n","submission = submission.merge(test_meta, on=\"game_episode\", how=\"left\")\n","\n","preds_x, preds_y = [], []\n","\n","path = \"/content/drive/MyDrive/1데이콘/Track1알고리즘부문:K리그-서울시립대공개AI경진대회/dataset\"\n","for _, row in tqdm(submission.iterrows(), total=len(submission)):\n","    # g = pd.read_csv(path + row[\"path\"]).reset_index(drop=True)\n","    # re_path = os.path.normpath(path + row['path'])\n","    p = row[\"path\"]\n","    print(p)\n","    main = p.rsplit('.', 1)[0]     # 확장자 제거한 부분\n","    ext  = p.rsplit('.', 1)[1]     # 확장자\n","    print(main)\n","    print(ext)\n","    main = main.replace('.', '/')\n","    file_path = main + '.' + ext\n","\n","    g = pd.read_csv(path + file_path).reset_index(drop=True)\n","    # 정규화된 좌표 준비\n","    sx = g[\"start_x\"].values / 105.0\n","    sy = g[\"start_y\"].values / 68.0\n","    ex = g[\"end_x\"].values / 105.0\n","    ey = g[\"end_y\"].values / 68.0\n","\n","    coords = []\n","    for i in range(len(g)):\n","        # start는 항상 존재하므로 그대로 사용\n","        coords.append([sx[i], sy[i]])\n","        # 마지막 행은 end_x가 NaN이므로 자동으로 제외됨\n","        if i < len(g) - 1:\n","            coords.append([ex[i], ey[i]])\n","\n","    seq = np.array(coords, dtype=\"float32\")  # [T, 2]\n","\n","    x = torch.tensor(seq).unsqueeze(0).to(DEVICE)      # [1, T, 2]\n","    length = torch.tensor([seq.shape[0]]).to(DEVICE)   # [1]\n","\n","    with torch.no_grad():\n","        pred = model(x, length).cpu().numpy()[0]       # [2], 정규화 좌표\n","\n","    preds_x.append(pred[0] * 105.0)\n","    preds_y.append(pred[1] * 68.0)\n","print(\"Inference Done.\")\n","\n","\n","submission[\"end_x\"] = preds_x\n","submission[\"end_y\"] = preds_y\n","submission[[\"game_episode\", \"end_x\", \"end_y\"]].to_csv(\"/content/drive/MyDrive/1데이콘/Track1알고리즘부문:K리그-서울시립대공개AI경진대회/submission.csv\", index=False)\n","print(\"Saved: baseline_submit.csv\")"]}]}